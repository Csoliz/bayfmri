{
 "metadata": {
  "name": "Multiple_comparison"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Multiple comparisons"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline # first set up inline plotting "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.kernel.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Nubmer of test significant at the 0.050000 level: 5 \n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The problem occurs when you permform several statistical tests: by chance, some will be significant even if the data has been generated under the null hypothesis.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "FWER : Bonferroni"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imaging you are doing $n$ t tests each one with a risk of type one error of $\\alpha$, and we denote by $t_\\alpha$ the t-value such that for a variable t drawn from a Student distribution, we have $P(t < t_\\alpha) = \\alpha$,   the probability of getting at least one significant test is these n tests is : "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\n",
      "\\alpha_{F} = P(\\textrm{ one or more } t_i > t_\\alpha) = 1 - \\prod_{i} P(t_i < t_\\alpha) = 1 - (1 - \\alpha)^n \n",
      "$$ \n",
      "\n",
      "$$\n",
      "\\alpha = 1 -(1 - \\alpha_{F})^{\\frac{1}{n}} = 1 - \\exp\\left(\\frac{1}{n} \\log(1 - \\alpha_{F})\\right)\n",
      "$$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code demo: a t-distribution\n",
      "from scipy.stats import t as tdist\n",
      "df = 14\n",
      "n = 100\n",
      "alph = .05\n",
      "\n",
      "# Often easier to compute the static distribution of t with df : t14 = tdist(df)\n",
      "# rvs : draw one or several random variables\n",
      "ts = tdist(df).rvs(size=n)\n",
      "\n",
      "# The threshold as a t value: \n",
      "t_alph = tdist.isf(alph,df)\n",
      "\n",
      "print \"Nubmer of test significant at the %f level: %d \" %(alph, sum(ts >= t_alph))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Nubmer of test significant at the 0.050000 level: 8 \n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To correct for the number of tests with the Bonferroni correction :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if we have p values : \n",
      "p = tdist(df).sf(ts)\n",
      "p_corr = (1 - (1 - p)**n)\n",
      "print \"Number of test significant with uncorrected threshold: %d, corrected: %d \", \\\n",
      "            sum(p <= alph), sum(p_corr <= alph)\n",
      "\n",
      "# This can be put in a little function:\n",
      "def p_corrected(ps):\n",
      "    return( 1 - (1 - p)**n )\n",
      "\n",
      "# alternatively : compare orginal p with : 1.0 - exp(1./n * log(1 - .05))\n",
      "\n",
      "def alph_corr(alph,n):\n",
      "    return 1.0 - exp(1./n * log(1 - alph))\n",
      "\n",
      "print \"Uncorrected threshold: %f, corrected threshold: %f\" % (alph, alph_corr(alph,n))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of test significant with uncorrected threshold: %d, corrected: %d  9 0\n",
        "Uncorrected threshold: 0.050000, corrected threshold: 0.000256\n"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On average we would have to run about 20 times the previous code to get a (spurious) significant effect.\n",
      "\n",
      "Note that when the tests are NOT INDEPENDENT, then this procedure is conservative (on average you will get less false positive than the specified risk or error), and therefore not the most sensitive. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "False Detection Rate "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The false detection rate (introduced by Benjamini and Hochberg (1995), see [http://en.wikipedia.org/wiki/False_discovery_rate] for an history of this measure."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's denote : \n",
      "\n",
      "* $S$ the number of true positive\n",
      "* $V$ the number of false positives (Type I error)\n",
      "* $R$ is the number of rejected null hypotheses (also called \"discoveries\")\n",
      "* $Q$ the proportion of false discoveries amongst the discoveries = $\\frac{V}{S+V}$\n",
      "\n",
      "We want to control such that $Q = \\frac{V}{S+V} = \\frac{V}{R}$ is small. \n",
      "\n",
      "The false discovery rate is the expectation of the false discovery proportion $\\textrm{FDR} = E(Q)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The procedure : step by step.\n",
      "\n",
      "First, we order the p-values by increasing order. We start to test the smallest p-value (the highest t or z), and declare the test significant if its p-value is less than $\\alpha/n$, for instance $0.05/n$. If this test is significant, we test the following pOur new threshold to declare significance is $\\alpha * 2 /n)$. This is iterated, until a test is not significant. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\n",
      "T_{BH} = \\textrm{max} \\left \\{ { P_{(i)} : P_{(i)} < \\frac{\\alpha i }{n} } \\right  \\}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An intuition : $i  \\frac{\\alpha}{n} $ is the expected value if I draw $i$ times in a bernouilli distribution of probability $ \\frac{\\alpha}{n} $ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's implement this and compare to Bonferroni or uncorrected thresolds:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats as st\n",
      "norm01 = st.norm(0,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# adapted from nipy/algorithms/statistics/empirical_pvalue\n",
      "#q = ( (range(n)+1)/n) * 0.05 ) \n",
      "\n",
      "def fdrcurve(z, distrib=norm01):\n",
      "        \"\"\"\n",
      "        Returns the FDR associated with any point of z\n",
      "        \"\"\"\n",
      "        n = len(z)\n",
      "        efp = distrib.sf(z) * n / np.arange(n, 0, - 1)\n",
      "        efp = np.minimum(efp, 1)\n",
      "        \n",
      "        ix = np.argsort(z)\n",
      "        \n",
      "        for i in range(np.size(efp) - 1, 0, - 1):\n",
      "            efp[ix[i - 1]] = np.maximum(efp[ix[i]], efp[ix[i - 1]])\n",
      "            \n",
      "        sorted_z = z[ix]\n",
      "        sorted_fdr = efp[ix]\n",
      "        \n",
      "        return efp, sorted_z, sorted_fdr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z = norm01.rvs(size=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "efp, sorted_z, sorted_fdr = fdrcurve(z)\n",
      "\n",
      "if len(z) <= 20:\n",
      "    print \"z \\n\", z \n",
      "    print \"efp \\n\", efp\n",
      "    print \"sorted_z \\n\", sorted_z\n",
      "    print \"sorted_fdr \\n\", sorted_fdr\n",
      "else:\n",
      "    print sum(sorted_fdr < .05)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "z \n",
        "[ 0.44625995  2.12711268  1.61239233  1.70035189  1.36279965  1.09673871\n",
        " -0.0908806   0.89395441  0.21074389  0.53852913  1.18518329 -1.57768962\n",
        "  0.51715978 -0.044914   -0.94923382  1.36617211 -0.28814578  0.18603415\n",
        " -0.44390997 -0.86316004]\n",
        "efp \n",
        "[ 0.75630578  0.01758459  0.05937588  0.05239103  0.3437699   0.3437699   1.\n",
        "  0.3437699   0.75630578  0.53655618  0.3437699   1.          0.75630578\n",
        "  1.          1.          0.3437699   1.          1.          1.          1.        ]\n",
        "sorted_z \n",
        "[-1.57768962 -0.94923382 -0.86316004 -0.44390997 -0.28814578 -0.0908806\n",
        " -0.044914    0.18603415  0.21074389  0.44625995  0.51715978  0.53852913\n",
        "  0.89395441  1.09673871  1.18518329  1.36279965  1.36617211  1.61239233\n",
        "  1.70035189  2.12711268]\n",
        "sorted_fdr \n",
        "[ 1.          1.          1.          1.          1.          1.          1.\n",
        "  1.          0.75630578  0.75630578  0.75630578  0.53655618  0.3437699\n",
        "  0.3437699   0.3437699   0.3437699   0.3437699   0.05937588  0.05239103\n",
        "  0.01758459]\n"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = 14\n",
      "t14 = tdist(df)\n",
      "n = 200\n",
      "ts = t14.rvs(size=n)\n",
      "# ts = np.sort(ts)           # careful of ts = ts.sort() .... you get None !!!\n",
      "# ts[:-int(n*.1):-1] += 1\n",
      "ps = t14.sf(ts)\n",
      "\n",
      "#uncorrected :\n",
      "print  'Uncorrected: ',sum(ps < alph)\n",
      "\n",
      "#Bonferroni : \n",
      "print 'Bonferroni: ',sum(ps < alph_corr(alph,n))\n",
      "\n",
      "#FDR : (suppose z)\n",
      "efp, sorted_z, sorted_fdr = fdrcurve(ts, distrib=t14)\n",
      "print 'FDR: ',sum(efp < alph)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Uncorrected:  8\n",
        "Bonferroni:  0\n",
        "FDR:  2\n"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adding signal :\n",
      "z = st.norm.rvs(0,1, size=n)\n",
      "print sum(z>1.5)\n",
      "z = z[z>1.5]+1\n",
      "efp, sorted_z, sorted_fdr = fdrcurve(z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10\n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "FWER : RFT"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}