{
 "metadata": {
  "name": "Multiple_comparison"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Multiple comparisons"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The problem occurs when you permform several statistical tests: by chance, some will be significant even if the data has been generated under the null hypothesis.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "FWER : Bonferroni"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imaging you are doing $n$ t tests each one with a risk of type one error of $\\alpha$, and we denote by $t_\\alpha$ the t-value such that for a variable t drawn from a Student distribution, we have $P(t < t_\\alpha) = \\alpha$,   the probability of getting at least one significant test is these n tests is : "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\n",
      "\\alpha_{F} = P(\\textrm{ one or more } t_i > t_\\alpha) = 1 - \\prod_{i} P(t_i < t_\\alpha) = 1 - (1 - \\alpha)^n \n",
      "$$ \n",
      "\n",
      "$$\n",
      "\\alpha = 1 -(1 - \\alpha_{F})^{\\frac{1}{n}} = 1 - \\exp\\left(\\frac{1}{n} \\log(1 - \\alpha_{F})\\right)\n",
      "$$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "\n",
      "# code demo:\n",
      "from scipy.stats import t as tdist\n",
      "df = 14\n",
      "n = 100\n",
      "alph = .05\n",
      "\n",
      "# Often easier to compute the static distribution of t with df : t14 = tdist(df)\n",
      "# rvs : draw one or several random variables\n",
      "ts = tdist(df).rvs(size=n)\n",
      "\n",
      "# The threshold as a t value: \n",
      "t_alph = tdist.isf(alph,df)\n",
      "\n",
      "print \"Nubmer of test significant at the %f level: %d \" %(alph, sum(ts >= t_alph))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.kernel.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Nubmer of test significant at the 0.050000 level: 5 \n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To correct for the number of tests, we use :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if we have p values : \n",
      "p = tdist(df).sf(ts)\n",
      "p_corr = (1 - (1 - p)**n)\n",
      "print sum(p <= .05), sum(p_corr <= .05)\n",
      "\n",
      "def p_corrected(ps):\n",
      "    return( 1 - (1 - p)**n )\n",
      "\n",
      "# alternatively : compare p with \n",
      "print 1.0 - exp(1./n * log(1 - .05))\n",
      "\n",
      "def alph_corr(alph):\n",
      "    return 1.0 - exp(1./n * log(1 - alph))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5 0\n",
        "0.000512801416262\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On average we would have to run about 20 times the previous code to get a (spurious) significant effect.\n",
      "\n",
      "Note that when the tests are NOT INDEPENDENT, then this procedure is conservative (on average you will get less false positive than the specified risk or error), and therefore not the most sensitive. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "FWER : RFT"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "False Detection Rate "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The false detection rate (introduced by Benjamini and Hochberg (1995), see [http://en.wikipedia.org/wiki/False_discovery_rate] for an history of this measure."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's denote : \n",
      "\n",
      "* $S$ the number of true positive\n",
      "* $V$ the number of false positives (Type I error)\n",
      "* $R$ is the number of rejected null hypotheses (also called \"discoveries\")\n",
      "* $Q$ the proportion of false discoveries amongst the discoveries = $\\frac{V}{S+V}$\n",
      "\n",
      "We want to control such that $Q = \\frac{V}{S+V} = \\frac{V}{R}$ is small. \n",
      "\n",
      "The false discovery rate is the expectation of the false discovery proportion $\\textrm{FDR} = E(Q)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The procedure : step by step.\n",
      "\n",
      "Suppose we start to test the smallest p-value (the highest t or z). As we are doing $n$ tests, we should correct for the multiple comparison, and declare the test significant if its p-value is less than $\\alpha/n$, for instance 0.05. If this test is significant, (we can assume we have one true positive). Our new threshold to declare significance is $\\alpha * 2 /n)$. This is iterated, until a test is not significant. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\n",
      "T_{BH} = \\textrm{max} \\left \\{ { P_{(i)} : P_{(i)} < \\frac{\\alpha i }{n} } \\right  \\}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An intuition : $i  \\frac{\\alpha}{n} $ is the expected value if I draw $i$ times in a bernouilli distribution of probability $ \\frac{\\alpha}{n} $ "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = 14\n",
      "t14 = tdist(df)\n",
      "n = 1000\n",
      "\n",
      "ts = t14.rvs(size=n)\n",
      "ts = np.sort(ts) # careful of ts = ts.sort() .... you get None !!!\n",
      "ts[:-int(n*.1):-1] += 1\n",
      "ps = t14.sf(ts)\n",
      "\n",
      "#uncorrected\n",
      "print  'Uncorrected: ',sum(ps < .05)\n",
      "\n",
      "#Bonferroni\n",
      "print 'Bonferroni: ',sum(ps < alph_corr(.05))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Uncorrected:  99\n",
        "Bonferroni:  0\n",
        "1000\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 10\n",
      "print np.arange(n, 0, -1)\n",
      "1.0 * n / np.arange(n, 0, - 1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10  9  8  7  6  5  4  3  2  1]\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array([  1.        ,   1.11111111,   1.25      ,   1.42857143,\n",
        "         1.66666667,   2.        ,   2.5       ,   3.33333333,\n",
        "         5.        ,  10.        ])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats as st\n",
      "#FDR\n",
      "#q = ( (range(n)+1)/n) * 0.05 ) \n",
      "# adapted from nipy/algo/stat/empirical_pvalue\n",
      "\n",
      "def fdrcurve(z, mu=0, sigma=1.):\n",
      "        \"\"\"\n",
      "        Returns the FDR associated with any point of self.x\n",
      "        \"\"\"\n",
      "        n = len(z)\n",
      "        efp = st.norm.sf(z, mu, sigma) * n / np.arange(n, 0, - 1)\n",
      "        efp = np.minimum(efp, 1)\n",
      "        \n",
      "        ix = np.argsort(z)\n",
      "        \n",
      "        for i in range(np.size(efp) - 1, 0, - 1):\n",
      "            efp[ix[i - 1]] = np.maximum(efp[ix[i]], efp[ix[i - 1]])\n",
      "            \n",
      "        sorted_z = z[ix]\n",
      "        sorted_fdr = efp[ix]\n",
      "        \n",
      "        return efp, sorted_z, sorted_fdr\n",
      "\n",
      "\n",
      "#print np.argmax( "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z = st.norm.rvs(0,1, size=20)\n",
      "efp, sorted_z, sorted_fdr = fdrcurve(z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print z, \"\\n\"\n",
      "print efp, \"\\n\"\n",
      "print sorted_z, \"\\n\"\n",
      "print sorted_fdr, \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-0.65516174  0.74800237 -0.36655991 -0.4204254  -0.88316314  0.84659919\n",
        "  1.60601269 -1.36591149 -0.80562132 -0.07596366  0.39860776  0.13725318\n",
        " -0.21390712  1.14290404 -0.50501858 -0.52926819  0.56327594 -2.47596805\n",
        "  0.48404538 -0.40365749] \n",
        "\n",
        "[ 1.          0.36154062  1.          1.          1.          0.36154062\n",
        "  0.07733652  1.          1.          1.          1.          1.          1.\n",
        "  0.36154062  1.          1.          1.          1.          1.          1.        ] \n",
        "\n",
        "[-2.47596805 -1.36591149 -0.88316314 -0.80562132 -0.65516174 -0.52926819\n",
        " -0.50501858 -0.4204254  -0.40365749 -0.36655991 -0.21390712 -0.07596366\n",
        "  0.13725318  0.39860776  0.48404538  0.56327594  0.74800237  0.84659919\n",
        "  1.14290404  1.60601269] \n",
        "\n",
        "[ 1.          1.          1.          1.          1.          1.          1.\n",
        "  1.          1.          1.          1.          1.          1.          1.\n",
        "  1.          1.          0.36154062  0.36154062  0.36154062  0.07733652] \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}