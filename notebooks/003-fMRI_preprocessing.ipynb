{
 "metadata": {
  "name": "003-fMRI_preprocessing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "fMRI Preprocessing\n",
      "==================\n",
      "In this section of the workshop, we'll investigate some of the typical problems in fMRI data, such as the effects of subject motion and physiological noise, and the algorithms that are often used to fix them. We'll show you how to:\n",
      "\n",
      "* look at some simple data quality metrics\n",
      "* run motion correction\n",
      "* explore physiological noise correction\n",
      "\n",
      "The dataset that we are using is the Duncan et. al. [word and object processing data](https://openfmri.org/dataset/ds000107) from [openfmri](https://openfmri.org/). It was acquired on a Siemens 1.5T scanner at 3x3x3 mm resolution and a TR of 3 seconds. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data quality: a single subject\n",
      "------------------------------\n",
      "First we need to set up our environment with some now-familiar imports."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import os # Module with commands to interact with the operating system\n",
      "import numpy as np # this is the Python package for handling arrays\n",
      "import matplotlib.pyplot as plt # This is for making 2D plots like MATLAB\n",
      "import nibabel as nib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's load a time series of images for the first subject."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATA_DIR = os.path.abspath('ds107') # The absolute path to the data directory\n",
      "SUBJ1_DIR = os.path.join(DATA_DIR, 'sub001')\n",
      "s1_bold_fname = os.path.join(SUBJ1_DIR, 'BOLD', 'task001_run001', 'bold.nii.gz')\n",
      "s1_bold_img = nib.load(s1_bold_fname)\n",
      "s1_bold_arr = s1_bold_img.get_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need a convenient way to view 3d volume data as 2d images. Here we define a simple function that will creat a montage of all the slices in a volume."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def montage(vol):\n",
      "    \"\"\"Returns a 2d image monage given a 3d volume.\"\"\"\n",
      "    num_cols = int(np.ceil(np.sqrt(vol.shape[2])))\n",
      "    rows = np.array_split(vol, num_cols, axis=2)\n",
      "    # ensure the last row is the same size as the others\n",
      "    rows[-1] = np.dstack((rows[-1], np.zeros(rows[-1].shape[0:2] + (rows[0].shape[2]-rows[-1].shape[2],))))\n",
      "    im = np.vstack([np.squeeze(np.hstack(np.dsplit(row, num_cols))) for row in rows])\n",
      "    return(im)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Temporal mean\n",
      "Let's look at the mean across time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temporal_mean = s1_bold_arr.mean(axis=3)\n",
      "figure(figsize=(8,8))\n",
      "plt.imshow(montage(temporal_mean), cmap='gray')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Temporal standard deviation\n",
      "Show the temporal standard deviation. This will indicate spatial regions that have high temporal fluctuations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temporal_std = s1_bold_arr.std(axis=3) # the last axis (0-based numbering)\n",
      "figure(figsize=(8,8))\n",
      "plt.imshow(montage(temporal_std), cmap='hot')\n",
      "plt.colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Computing the temporal standard devaition collapses across time and can show spatial regions (like the brain edge) where there might be problems in the data. Note the regions of high variance around the edges of the brain. What might be causing that?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### RMS Error over time\n",
      "Now let's comute a metric that will collapse across space to help us see *temporal* regions that have high variance. We'll use the root mean square error between each time point and the mean across time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_timepoints = s1_bold_arr.shape[3]\n",
      "rms = np.zeros(num_timepoints) # initialize an array to hold our rms values\n",
      "for t in range(num_timepoints):\n",
      "    squared_difference = (temporal_mean - s1_bold_arr[:,:,:,t])**2\n",
      "    rms[t] = np.sqrt(np.mean(squared_difference))\n",
      "plt.plot(rms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that we can take advantage of numpy's powerful broadcasting rules to make the above code much more efficient by removing the loop. First, we have to get the two arrays to have the same number of dimensions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temporal_mean = s1_bold_arr.mean(axis=3)\n",
      "temporal_mean = temporal_mean.reshape(temporal_mean.shape + (1,))\n",
      "(temporal_mean.shape, s1_bold_arr.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can let numpy do the loop by \"broadcasting\" the smaller array across the larger one. Note also how we chain together three .mean methods to collapse across the three spatial dimensions. Let's look at thow that works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(squared_difference.shape, \n",
      " squared_difference.mean(axis=0).shape, \n",
      " squared_difference.mean(axis=0).mean(axis=0).shape, \n",
      " squared_difference.mean(axis=0).mean(axis=0).mean(axis=0).shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "squared_difference = (temporal_mean - s1_bold_arr)**2\n",
      "rms = np.sqrt(squared_difference.mean(axis=0).mean(axis=0).mean(axis=0))\n",
      "plt.plot(rms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now what if we wanted to look at another subject? Pick a subject and try to make a plot of the RMS error."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bold_fname = os.path.join(os.path.join(DATA_DIR, 'sub003'), 'BOLD', 'task001_run001', 'bold.nii.gz')\n",
      "bold_arr = nib.load(bold_fname).get_data()\n",
      "temporal_mean = bold_arr.mean(axis=3)\n",
      "temporal_mean = temporal_mean.reshape(temporal_mean.shape + (1,))\n",
      "squared_difference = (temporal_mean - bold_arr)**2\n",
      "rms = np.sqrt(squared_difference.mean(axis=0).mean(axis=0).mean(axis=0))\n",
      "plt.plot(rms)\n",
      "# also try sub038"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Certain EPI artifacts (such as *white pixel noise*, also known as spike artifacts) affect one or two slices. By taking the RMS error across the entire volume, we might miss such problems. How might we modify the above code to compute and plot the RMS error for one slice? Or for all slices, but plotting each slice separately? Let's take a moment to write this code together."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE\n",
      "# Compute the RMS error for one slice. Then modify it to do the same across all slices.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data quality metrics across all subjects\n",
      "----------------------------------------\n",
      "Now let's look at some simple data quality metrics for all the subjects. First we'll get a list of all the subject data directories and display it nicely using a powerful tool in python called a *list comprehension*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_subs = os.listdir(DATA_DIR)\n",
      "# show the list, exploiting the fact that a string is an iterable container of one-character strings\n",
      "print \", \".join([s for s in all_subs])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Oops-- there are a couple of other files in there. We'll use another list comprehension to get a clean list of subject directories:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_subs = [s for s in os.listdir(DATA_DIR) if \"sub\" in s]\n",
      "print \", \".join([s for s in all_subs])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Check image dimensions\n",
      "Now that we have a clean list of all the subject directories, let's loop across subjects and check the image dimensions of the images as a basic quality assurance metric."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_subjects = len(all_subs)\n",
      "dims_all = np.zeros((num_subjects, 4)) # initialize an array to hold our data array dimensions\n",
      "for sub_index,sub_dir in enumerate(all_subs):\n",
      "    bold_fname = os.path.join(DATA_DIR, sub_dir, 'BOLD', 'task001_run001', 'bold.nii.gz')\n",
      "    dims_all[sub_index,:] = nib.load(bold_fname).get_shape()\n",
      "\n",
      "print \"min=\" + str(dims_all.min(axis=0)) + \", max=\"+ str(dims_all.max(axis=0)) + \", median=\" + str(np.median(dims_all, axis=0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It looks like not all the subjects have the same number of temporal frames. If this were our data, we'd go back and try to figure out what happened. Maybe we mispecified the scan parameters and acquired an extra frame or two at the start? Or at the end? Try writing a little code to print a list of the subjects and the data dimensions for each."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE\n",
      "# Print a list of subjects and the data dimensions for each"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But since this isn't our data, we'll just forge on, assuming the extra frames are at the end and setting num_timepoints to the minimum. ([The oiginal paper](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2686646/) claims that there were 164 volumes for each subject.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_timepoints = int(dims_all.min(axis=0)[3])\n",
      "print num_timepoints"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### RMS error for each subject\n",
      "Loop across subjects again to compute the rms error for all of them. The loop above was fast, because we only needed to load the header for each subject to get the image dimensions. But this time we have to load the entire data array for each subject. So this loop will take a couple of minutes to run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rms_all = np.zeros((num_subjects, num_timepoints)) # initialize an array to hold our rms values\n",
      "for sub_index,sub_dir in enumerate(all_subs):\n",
      "    bold_fname = os.path.join(DATA_DIR, sub_dir, 'BOLD', 'task001_run001', 'bold.nii.gz')\n",
      "    bold_arr = nib.load(bold_fname).get_data()\n",
      "    temporal_mean = bold_arr.mean(axis=3).reshape(bold_arr.shape[0:3] + (1,))\n",
      "    squared_difference = (temporal_mean - bold_arr)**2\n",
      "    rms_all[sub_index,:] = np.sqrt(squared_difference.mean(axis=0).mean(axis=0).mean(axis=0))[0:num_timepoints]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now plot the RMS results. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for rms_s in rms_all:\n",
      "    plt.plot(rms_s)\n",
      "plt.xlabel('Time (TR)')\n",
      "plt.ylabel('RMS Error')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It looks like some subjects have some time points with very large deviations. There also appears to be a trend across all the subjects:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(rms_all.mean(axis=0))\n",
      "plt.xlabel('Time (TR)')\n",
      "plt.ylabel('RMS Error')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is much more deviation at the beginning and end of the run. Why is that? One possibility is motion. Let's motion-correct the worst subject's data and then have another look. First, we have to find that subject:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_rms_all = rms_all.mean(axis=1)\n",
      "worst_subject = np.nonzero(mean_rms_all==mean_rms_all.max())[0][0]\n",
      "worst_subject"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Motion Correction for One Subject\n",
      "---------------------------------\n",
      "Now we'll run motion correction, first on one subject, then on the whole group. We'll use a 4d alignment algorithm that will also incorporate a slice-time correction. See [the paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05737791) on this by Alexis Roche for details. We begin by importing the relevant module from [NiPy](http://nipy.sourceforge.net/)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nipy\n",
      "from nipy.algorithms import registration"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worst_bold_fname = os.path.join(DATA_DIR, all_subs[worst_subject], 'BOLD', 'task001_run001', 'bold.nii.gz')\n",
      "worst_bold_img = nib.load(worst_bold_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To properly do the slice-time correction, we need to know the slice acquisition order. Ideally, you will get this from the image header. Unfortunately, that information is not always set properly, as in the data that we are analyzing:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worst_bold_hdr = worst_bold_img.get_header()\n",
      "worst_bold_hdr.get_slice_times()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the header isn't set properly, then you just need to know how the data were acquired."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slice_order = range(worst_bold_img.get_shape()[2])\n",
      "print slice_order"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also need to know the TR. That should also be stored in the header. For a NIFTI file, it is (somewhat cryptically) stored along with the spatial voxel dimensions. Think of it as defining the temporal step-size, just as the voxel dimensions define the spatial step-size. In Nibabel, the scale factors are called *zooms*. (Maybe because it was written by a Brit?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xyzt = worst_bold_hdr.get_zooms()\n",
      "print xyzt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Run the 4D realignment\n",
      "First we set up the realignment object"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TR = xyzt[3]\n",
      "realign = nipy.algorithms.registration.FmriRealign4d(worst_bold_img, slice_order, tr=TR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Estimating the motion parameters takes about 2.5 minutes on ipython.stanford.edu."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "realign.estimate(loops=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot the motion parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the list of transforms, one for each time frame\n",
      "transforms = realign._transforms[0]\n",
      "# form a single array of shape transform parameter X time\n",
      "motion_params = np.vstack([t.param for t in transforms])\n",
      "plt.plot(motion_params)\n",
      "xlabel('time (TR)')\n",
      "ylabel('motion (mm)')\n",
      "legend(('tx','ty','tz','r1','r2','r3'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Compute and plot the mean displacement\n",
      "Let's summarize the motion more simply by plotting the total RMS displacement integrated over the brain volume (modeled as a sphere). See this [FSL tech report](http://www.fmrib.ox.ac.uk/analysis/techrep/tr99mj1/tr99mj1/tr99mj1.html) by Mark Jenkinson for details."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "R = 70. # radius of the spherical head assumption\n",
      "ref_affine = np.matrix(worst_bold_img.get_affine()) # use numpy's matrix type to make the matrix math nicer\n",
      "mean_displacement = np.zeros((num_timepoints))\n",
      "for index,t in enumerate(transforms[0:num_timepoints]):\n",
      "    # get the full affine for this volume by pre-multiplying by the reference affine\n",
      "    this_mc_affine = ref_affine * t.as_affine()\n",
      "    # Compute the error matrix\n",
      "    T_error = ref_affine - this_mc_affine\n",
      "    # extract the rotation matrix (the upper 3x3)\n",
      "    A = T_error[0:3,0:3]\n",
      "    # extract the translations\n",
      "    t = T_error[0:3,3]\n",
      "    # The center of the volume. Assume 0,0,0 in world coordinates.\n",
      "    xc = np.matrix((0,0,0)).T\n",
      "    mean_displacement[index] = np.sqrt( R**2. / 5 * np.trace(A.T * A) + (t + A*xc).T * (t + A*xc) )\n",
      "plt.plot(mean_displacement)\n",
      "plt.xlabel('Time (TRs)')\n",
      "plt.ylabel('Mean Displacement (mm)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Resample the data\n",
      "Note that the step above where we *estimated* the motion parameters has not actually done motion correction! It's simply computed the adjustments needed to minimize the error between each time point and the reference volume (the first volume, in this case). To actually apply the motion correction, we need to use the motion parameters that we computed to *resample* the data, creating a new data set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worst_bold_img_mc = realign.resample()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Check motion correction results\n",
      "First let's have a look at the mean across time for both the original and motion-corrected data sets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worst_arr_mc = worst_bold_img_mc[0].get_data()\n",
      "worst_arr_mc_mean = worst_arr_mc.mean(axis=3)\n",
      "worst_arr_mean = worst_bold_img.get_data().mean(axis=3)\n",
      "fig = figure(figsize=(18,6))\n",
      "fig.add_subplot(131, title=\"Original\").imshow(montage(worst_arr_mean), cmap='gray')\n",
      "fig.add_subplot(132, title=\"Motion Corrected\").imshow(montage(worst_arr_mc_mean), cmap='gray')\n",
      "fig.add_subplot(133, title=\"Difference\").imshow(montage(worst_arr_mean-worst_arr_mc_mean), cmap='gray')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now compute the RMS error for that bad subject and plot the results, comparing to the uncorrected RMS."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "squared_difference = (worst_arr_mc_mean.reshape(worst_arr_mc_mean.shape + (1,)) - worst_arr_mc)**2\n",
      "worst_rms_mc = np.sqrt(squared_difference.mean(axis=0).mean(axis=0).mean(axis=0))[0:num_timepoints]\n",
      "plt.plot(rms_all[worst_subject])\n",
      "plt.plot(worst_rms_mc)\n",
      "legend(('uncorrected RMS','corrected RMS'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at the RMS error for each slice separately. We'll write that code together."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE\n",
      "# plot the RMS error for this bad subject for each slice separately"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Motion correction for all subjects\n",
      "----------------------------------\n",
      "Here's the code to run the realignment and resampling on all the subects. It takes a while to run, so we ran it earlier and saved the results."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "realign_all = [] # initialize a list to hold all the realign params\n",
      "mean_displacement_all = np.zeros((num_subjects, num_timepoints))\n",
      "xc = np.matrix((0,0,0)).T\n",
      "for sub_index,sub_dir in enumerate(all_subs):\n",
      "    bold_fname = os.path.join(DATA_DIR, sub_dir, 'BOLD', 'task001_run001', 'bold.nii.gz')\n",
      "    bold_img = nib.load(bold_fname)\n",
      "    realign = nipy.algorithms.registration.FmriRealign4d(bold_img, 'ascending', tr=TR)\n",
      "    realign.estimate(loops=3)\n",
      "    # Compute the mean displacement\n",
      "    ref_affine = np.matrix(bold_img.get_affine())\n",
      "    transforms = realign._transforms[0]\n",
      "    for time_index,t in enumerate(transforms[0:num_timepoints]):\n",
      "        T_error = ref_affine - ref_affine * t.as_affine()\n",
      "        A = T_error[0:3,0:3]\n",
      "        t = T_error[0:3,3]\n",
      "        mean_displacement_all[sub_index,time_index] = np.sqrt(R**2. / 5 * np.trace(A.T * A) + (t + A*xc).T * (t + A*xc))\n",
      "     # save all the realignment parameters\n",
      "    realign_all.append(realign)\n",
      "    bold_img_mc = realign.resample()[0]\n",
      "    ni = nib.Nifti1Image(bold_img_mc.get_data(), bold_img.get_affine())\n",
      "    nib.save(ni, sub_dir + '_task001_run001_bold_mc.nii.gz')\n",
      "np.savetxt('mean_displacement_all.csv', mean_displacement_all)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Check the motion correction results\n",
      "Let's plot the mean displacement for all the subjects to see how they did in keeping still."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_displacement_all = np.loadtxt('mean_displacement_all.csv')\n",
      "plt.figure(figsize=(12,6))\n",
      "for m in mean_displacement_all:\n",
      "    plt.plot(m)\n",
      "# Also plot the mean across subjects\n",
      "plt.plot(mean_displacement_all.mean(axis=0), color='black', linestyle='dashed', linewidth=5.)\n",
      "xlabel('Time (TR)')\n",
      "ylabel('Mean Displacement (mm)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It looks like all subjects have some slow drift over time. Any descent motion correction algorithm should be able to fix that. But quick, jerky movements will introduce other artifacts that are not easy to fix with a rigid-body motion correction. For example, rapid motion during the EPI read-out will introduce non-linear geometric distortions and possible ghosting. The spin history of each voxel will also change abruptly, causing an overall increase or decrease in signal intensity. Let's compute a simple metric to find the worst subjects.\n",
      "\n",
      "First, we'll have a look at the numerical derivative of the mean displacement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "md_diff = np.diff(mean_displacement_all)\n",
      "plt.figure(figsize=(12,6))\n",
      "for m in md_diff:\n",
      "    plt.plot(m)\n",
      "xlabel('Time (TR)')\n",
      "ylabel('Mean Displacement change (mm)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set a maximum displacement threshold (somewhat arbitrarily)\n",
      "max_disp = 2.5\n",
      "md_diff_rms = np.sqrt(np.sum(md_diff**2, axis=1))\n",
      "plt.figure(figsize=(12,5))\n",
      "plt.bar(range(num_subjects), md_diff_rms)\n",
      "plt.plot([0,num_subjects], [max_disp,max_disp], color='gray', linestyle='dashed')\n",
      "xlabel('Subject Index')\n",
      "ylabel('RMS mean displacement change')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bad_sub_inds = np.nonzero(md_diff_rms >= max_disp)[0]\n",
      "print [all_subs[s] for s in bad_sub_inds]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perhaps these subjects should be scrutinized more closely. Having a look at the scan notes might be a good idea to see if there was a problem during acquisition. What metrics might we use to further investigate the problematic subjects?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CODE HERE\n",
      "# Implement a data quality metric to investigate the data for the subjects with a lot of motion.\n",
      "# Maybe start by looking at the actual images themselves?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}